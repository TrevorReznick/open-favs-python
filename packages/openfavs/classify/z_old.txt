  # @@ testing find similarities and spli sentences @@ #

    """matches = find_partial_matches(description, Config.SUGGESTIONS)

    for match in matches:
        print(f"Found match: {match[0]} -> {match[1]}")
    """

    # 1. Suddividi la frase in sottofrasi
    sub_phrases = split_sentence(description)
    #print(f"Sub-phrases: {sub_phrases}")

    # 2. Crea un dizionario delle sottofrasi
    phrases_dict = create_phrases_dict(sub_phrases)
    #print(f"Phrases dictionary: {phrases_dict}")

    suggestions_found = {}
    suggestion = ""


    
    refactor_prompt = refactor_classify_agent(my_string, name, title, description, html_content)
    re_re_classify = AI.asks_ai(refactor_prompt, Config.SUPERVISOR_ROLE)
    #print('hello, refactor prompt!')
    #print('third prompt: ', re_re_classify)
 
 refining_prompt = create_reclassify_prompt(my_string, sub_cat_str, description, title)
    re_classify = AI.asks_ai(refining_prompt, Config.SUPERVISOR_ROLE)   
    #print('second prompt: ', re_classify)  
 
 prompt = create_classify_prompt(main_cat_str, description, suggestion, sub_cat_str)    
    classify = AI.asks_ai(prompt, Config.ROLE)
    #json_object = extract_json(classify, 'str_to_obj')
    #my_string = extract_my_string(classify, 'my_string')
    #result = {**json_object, **my_string} # Combina i risultati
    #print('first propmt: ', classify)
    """
prompt = create_classify_prompt(main_cat_str, description, suggestion, sub_cat_str)    
    classify = AI.asks_ai(prompt, Config.ROLE)
    json_object = extract_json(classify, 'str_to_obj')
    my_string = extract_my_string(classify, 'my_string')

def add_element(self, element, value):
    # Aggiunge una coppia chiave-valore al dizionario
    self.site_info[element] = value
    return self.site_info



title_tag = soup.find('title')
meta_description = soup.find('meta', attrs={"name": "description"})
description = soup.title.description
self.add_element('description', description)
#self.add_element('meta_description' , meta_description)
print("Debug Titolo:", title)
print('Debug title_tag: ', title_tag)
#print('Debug meta_description: ', meta_description)
if meta_description:
    print(meta_description['content'])  # Stampa il contenuto del tag meta description
    # Estrai il canonical link
    canonical_link = soup.find('link', attrs={'rel': 'canonical'})
    if canonical_link:
        print(canonical_link['href'])  # Stampa l'URL del canonical link
        tag_as_string = str(canonical_link)
        json_output = json.dumps({'content': tag_as_string}, ensure_ascii=False)
        self.add_element('canonical_link', json_output)
    # Estrai i metadati og:title
    #og_title = soup.find('meta', attrs={'property': 'og:title'})
    #if og_title:
    #print(og_title['content'])  # Stampa il contenuto del tag og:title
    #self.add_element('og_title', og_title)
    print('Debug description: ', description)
    return self.site_info
"""
for idx, sub_phrase in phrases_dict.items():

        matches = find_partial_matches_new(sub_phrase, Config.SUGGESTIONS)

        formatted_matches = [{k: v} for k, v in matches]

        if formatted_matches:  # Aggiungi solo se ci sono match
            suggestion_ = suggestions_found[sub_phrase] = formatted_matches
            suggestion_1 = [list(d.values())[0] for d in suggestion_]
            #print('suggestion', suggestion)
            suggestion = (" ".join(suggestion_1))
            #print('suggestion', suggestion)
        else:
            print('nessuna suggestion trovata')


        """if(matches):
            print(f"Matches for sub-phrase '{sub_phrase}': {matches}")
        else:
            print('nessuna suggestion trovata')"""